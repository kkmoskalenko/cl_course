# Computational Linguistics

## Практическое задание №1

> **Задача:** Построить частотный словарь по корпусу текстов.

1. Реализовать морфологический анализ (лемматизацию, определение части речи и морф. признаков)
   - можно использовать существующие ресурсы (`oDict`, разметку `OpenCorpora` и др.)
   - нельзя использовать существующие морфологические анализаторы (`mystem`, `pymorphy` и т.п.)

   **Вход:** корпус текстов.
   
   **Выход:** отсортированный по частоте словарь вида
   
   ````
   <лемма, ЧР, Num1>
   ````
   
4. Сопроводить решение документацией

### Функциональные требования

1. Графематический парсер текста
2. Лемматизация слова
3. Предоставление информации о морф. признаках слова
4. Разрешение лексической неоднозначности
5. Сбор статистики встречаемости (частота и текстовая частота)

### Анализ результатов

1. Оценка качества работы морфоанализатора
2. Анализ ошибок морфоанализатора
3. Исследование особенностей лексики заданного корпуса

## Практическое задание №2

> **Задача:** Реализовать метод построения конкордансов и вычисление частот совместной встречаемости.

1. Конкорданс строится для произвольной текстовой последовательности

2. Все слова вначале нормализуются (если слово не найдено, оно считается нормализованным)

3. Обеспечить сортировку по частоте левого и правого контекста

   **Вход:** корпус текстов (+словарь), фраза, размер окна (`n`), частотный порог (необ.).

   **Выход:** отсортированные по частоте контексты (длины не более `n`) фразы вначале левые, затем правые

   ```
   <л|п, норм_контекст, частота>
   ```

## Практическое задание №3

> **Задача:** Реализовать методы извлечения N-грамм.

1. Использовать свой морфоанализатор

2. Извлечь все повторяющиеся более одного раза цепочки (нормализовать)

3. Отфильтровать на основе оценки устойчивости

   **Вход:** корпус

   **Выход:** отсортированный словарь устойчивых N-грамм

   ```
   <N-грамма, Частота, Текстовая частота, TF-IDF>
   ```

4. Сопроводить решение документацией.

## Практическое задание №4

> **Задача:** Реализовать метод семантико-синтаксического анализа на основе моделей (10-20шт.).

1. Разработать модели для анализа текста. Записать на формальном языке (`JSON` / `XML` / `TXT`)

2. Реализовать методы поиска в корпусе ЕЯ-фрагментов, удовлетворяющих моделям

   **Вход:** корпус, файл с моделями

   **Выход:** списки найденных фрагментов

   ```
   <N модели, Кол-во вхождений, Фрагменты (каждый с новой строки)>
   ```

3. Оценить полноту / точность / F-меру
4. Сопроводить решение документацией

## Практическое задание №5

> **Задача:** Разработать поисковую систему на основе тезауруса специализированной области знаний.

1. Использовать свой корпус и словарь (включая N-граммы)

2. Создать тезаурус: разметить наиболее значимые термины словаря (~50 шт.: синонимы + общее-частное + ассоц.)

3. Реализовать метод поиска в корпусе на основе словаря используя отношения между терминами

   **Вход:** поисковые запрос на ЕЯ

   **Выход:** отсортированные по релевантности тексты (фрагменты текста)

   ```
   <N текста, Pos в тексте, Оценка>
   ```

4. Создать корпус запросов: не менее 20 запросов, с распределением ключевых терминов от 2-х до 6-ти в каждом запросе

5. Посчитать полноту / точность / F-меру поиска

6. Сопроводить решение документацией:

   - Описание решение
   - Описание эксперимента
   - Описание способа оценки (принятые ограничения)
   - Описание результатов, включая выявленные закономерности
   - Анализ ошибок
